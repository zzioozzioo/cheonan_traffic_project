{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2167e338",
   "metadata": {},
   "source": [
    "## [0ë‹¨ê³„] ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6453ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a680107",
   "metadata": {},
   "source": [
    "## [1ë‹¨ê³„] ì˜ˆì¸¡ ëª¨ë¸ ì„ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (LR) RMSE: 7.527587408906e-12\n",
      "Baseline (LR) MAE: 5.774439071210237e-12\n",
      "RF RMSE: 96.32553394208085\n",
      "RF MAE: 59.15137369635231\n",
      "XGB RMSE: 70.97879786312072\n",
      "XGB MAE: 41.228782653808594\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/merged/traffic_weather_with_cluster.csv\")     # (í´ëŸ¬ìŠ¤í„° í¬í•¨) ìµœì¢… ë°ì´í„° ë¡œë“œ\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])                         # datetime í˜• ë³€í™˜\n",
    "\n",
    "df['date'] = df['datetime'].dt.floor('D')                               # ë‚ ì§œ ì¶”ì¶œ \n",
    "df['hour'] = df['datetime'].dt.hour                                     # ì‹œê°„ ì¶”ì¶œ\n",
    "df[\"is_rain\"] = (df[\"precipitation\"] > 0).astype(int)                   # ê°•ìˆ˜ ì—¬ë¶€ ì´ì§„ ë³€ìˆ˜ ìƒì„± \n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"])                       # êµì°¨ë¡œë³„ ì‹œê°„ìˆœ ì •ë ¬ \n",
    "\n",
    "df[\"lag1\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(1)      # 1ì‹œê°„ ì „ êµí†µëŸ‰\n",
    "df[\"lag2\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(2)      # 2ì‹œê°„ ì „ êµí†µëŸ‰    \n",
    "df[\"lag3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(3)      # 3ì‹œê°„ ì „ êµí†µëŸ‰\n",
    "\n",
    "df[\"roll3\"] = (   # 3ì‹œê°„ ì´ë™ í‰ê· \n",
    "    df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "    .rolling(3).mean()\n",
    "    .reset_index(0,drop=True)\n",
    ")   \n",
    "df[\"roll6\"] = (   # 6ì‹œê°„ ì´ë™ í‰ê·   \n",
    "    df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "    .rolling(6).mean()\n",
    "    .reset_index(0,drop=True)\n",
    ")   \n",
    "\n",
    "df = df.dropna()    # lag, rollingìœ¼ë¡œ ìƒê¸´ ê²°ì¸¡ì¹˜ ì œê±°\n",
    "\n",
    "# Train / Test ë¶„ë¦¬ (ìµœê·¼ 30ì¼)\n",
    "test_size_days = 30\n",
    "split_date = df[\"date\"].max() - pd.Timedelta(days=test_size_days)   # ë¶„ê¸° ê¸°ì¤€ ë‚ ì§œ ì„¤ì •\n",
    "\n",
    "train = df[df[\"date\"] <= split_date]    # í•™ìŠµ ë°ì´í„°\n",
    "test  = df[df[\"date\"] > split_date]     # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "\n",
    "drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\"]\n",
    "\n",
    "X_train = train.drop(columns=drop_cols)    # í•™ìŠµ ì…ë ¥ ë³€ìˆ˜ \n",
    "y_train = train[\"traffic_volume\"]          # í•™ìŠµ íƒ€ê²Ÿ ë³€ìˆ˜ \n",
    "\n",
    "X_test = test.drop(columns=drop_cols)      # í…ŒìŠ¤íŠ¸ ì…ë ¥ ë³€ìˆ˜\n",
    "y_test = test[\"traffic_volume\"]            # í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ ë³€ìˆ˜ \n",
    "\n",
    "# í›„ë³´ 1) Linear Regression\n",
    "\n",
    "lr = LinearRegression()     # ì„ í˜• íšŒê·€ ëª¨ë¸ ìƒì„±\n",
    "lr.fit(X_train, y_train)    # ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "pred_lr = lr.predict(X_test)    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n",
    "\n",
    "rmse_lr = mean_squared_error(y_test, pred_lr) ** 0.5    # ì„ í˜• íšŒê·€ì˜ RMSE\n",
    "mae_lr = mean_absolute_error(y_test, pred_lr)           # ì„ í˜• íšŒê·€ì˜ MAE\n",
    "\n",
    "print(\"Baseline (LR) RMSE:\", rmse_lr)\n",
    "print(\"Baseline (LR) MAE:\", mae_lr)\n",
    "\n",
    "# í›„ë³´ 2) RandomForest\n",
    "rf = RandomForestRegressor(     # ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„±\n",
    "    n_estimators=200,           # íŠ¸ë¦¬ ê°œìˆ˜ \n",
    "    max_depth=12,               # íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)        # ëª¨ë¸ í•™ìŠµ\n",
    "pred_rf = rf.predict(X_test)    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n",
    "\n",
    "rmse_rf = mean_squared_error(y_test, pred_rf) ** 0.5    # ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ RMSE\n",
    "mae_rf = mean_absolute_error(y_test, pred_rf)           # ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ MAE\n",
    "\n",
    "print(\"RF RMSE:\", rmse_rf)\n",
    "print(\"RF MAE:\", mae_rf)\n",
    "\n",
    "# í›„ë³´ 3) XGBoost\n",
    "xgb = XGBRegressor(         # XGBoost ëª¨ë¸ ìƒì„±\n",
    "    n_estimators=500,       # ë¶€ìŠ¤íŒ… íŠ¸ë¦¬ ê°œìˆ˜\n",
    "    max_depth=8,            # íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´\n",
    "    learning_rate=0.05,     # í•™ìŠµë¥ \n",
    "    subsample=0.8,          # ìƒ˜í”Œ ë¹„ìœ¨\n",
    "    colsample_bytree=0.8,   # íŠ¹ì„± ìƒ˜í”Œë§ ë¹„ìœ¨\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)       # ëª¨ë¸ í•™ìŠµ\n",
    "pred_xgb = xgb.predict(X_test)  # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n",
    "\n",
    "rmse_xgb = mean_squared_error(y_test, pred_xgb) ** 0.5      # XGBoostì˜ RMSE   \n",
    "mae_xgb = mean_absolute_error(y_test, pred_xgb)             # XGBoostì˜ MAE\n",
    "\n",
    "print(\"XGB RMSE:\", rmse_xgb)\n",
    "print(\"XGB MAE:\", mae_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902b8f6",
   "metadata": {},
   "source": [
    "#### í…ŒìŠ¤íŠ¸ ê²°ê³¼, í˜„ì¬ ë°ì´í„° êµ¬ì¡°ì—ì„œëŠ” XGBoostê°€ ì í•©í•˜ë‹¤ê³  íŒë‹¨ -> XGBoostë¡œ ê³ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb529e4a",
   "metadata": {},
   "source": [
    "## [2ë‹¨ê³„] í…ŒìŠ¤íŠ¸ ê¸°ê°„(7, 30, 60, 90ì¼)ë³„ ì„±ëŠ¥ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_days    XGB_RMSE     XGB_MAE\n",
      "0          7  200.323254  114.959496\n",
      "1         30  168.213882   96.413803\n",
      "2         60  210.644936  118.021614\n",
      "3         90  203.655116  114.838440\n"
     ]
    }
   ],
   "source": [
    "# ì„ì˜ë¡œ íŠ¹ì • êµì°¨ë¡œ ì„ íƒ\n",
    "target = \"2ê³µë‹¨3\"\n",
    "df = df[df[\"intersection\"] == target].copy()\n",
    "\n",
    "\n",
    "df[\"roll3\"] = (   # 3ì‹œê°„ ì´ë™ í‰ê· \n",
    "df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "      .rolling(3).mean()\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df[\"roll6\"] = (   # 6ì‹œê°„ ì´ë™ í‰ê· \n",
    "    df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "      .rolling(6).mean()\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\"]\n",
    "\n",
    "# ë¹„êµí•  í…ŒìŠ¤íŠ¸ ê¸°ê°„ ëª©ë¡\n",
    "test_days_list = [7, 30, 60, 90]    \n",
    "results = []\n",
    "\n",
    "for test_days in test_days_list:\n",
    "\n",
    "    split_date = df[\"date\"].max() - pd.Timedelta(days=test_days)   # ë¶„ê¸° ê¸°ì¤€ ë‚ ì§œ ì„¤ì •\n",
    "\n",
    "    train = df[df[\"date\"] <= split_date]    # í•™ìŠµ ë°ì´í„°\n",
    "    test  = df[df[\"date\"] > split_date]     # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)   # í•™ìŠµ ì…ë ¥ ë³€ìˆ˜\n",
    "    y_train = train[\"traffic_volume\"]         # í•™ìŠµ íƒ€ê²Ÿ ë³€ìˆ˜  \n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)     # í…ŒìŠ¤íŠ¸ ì…ë ¥ ë³€ìˆ˜  \n",
    "    y_test = test[\"traffic_volume\"]           # í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ ë³€ìˆ˜  \n",
    "\n",
    "    # XGBoost ëª¨ë¸ë¡œ ì‹¤í–‰\n",
    "    xgb = XGBRegressor(         # XGBoost ëª¨ë¸ ìƒì„±\n",
    "        n_estimators=100,       # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "        max_depth=6,            # íŠ¸ë¦¬ ê¹Šì´\n",
    "        learning_rate=0.05,     # í•™ìŠµë¥ \n",
    "        random_state=42,        \n",
    "        subsample=0.8,          # ìƒ˜í”Œ ë¹„ìœ¨\n",
    "        colsample_bytree=0.8,   # íŠ¹ì„± ìƒ˜í”Œ ë¹„ìœ¨\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)        # ëª¨ë¸ í•™ìŠµ\n",
    "    pred_xgb = xgb.predict(X_test)   # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n",
    "\n",
    "    rmse_xgb = (mean_squared_error(y_test, pred_xgb)) ** 0.5    # RMSE\n",
    "    mae_xgb = mean_absolute_error(y_test, pred_xgb)             # MAE\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results.append({\n",
    "        \"test_days\": test_days,\n",
    "        \"XGB_RMSE\": rmse_xgb,\n",
    "        \"XGB_MAE\": mae_xgb\n",
    "    })\n",
    "\n",
    "\n",
    "# ê²°ê³¼ í‘œ ì¶œë ¥\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738cc88",
   "metadata": {},
   "source": [
    "#### í…ŒìŠ¤íŠ¸ ê²°ê³¼, í…ŒìŠ¤íŠ¸ ê¸°ê°„ì€ 30ì¼ì´ ê°€ì¥ ì„±ëŠ¥ì´ ìš°ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae950c",
   "metadata": {},
   "source": [
    "## [3ë‹¨ê³„] í´ëŸ¬ìŠ¤í„°ë³„ ëª¨ë¸ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac01e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 ë°ì´í„° ìˆ˜: 333426\n",
      "Cluster 1 ë°ì´í„° ìˆ˜: 251502\n",
      "\n",
      "==============================\n",
      "ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥ (ìµœì¢…)\n",
      "==============================\n",
      "[Cluster 0 - ì¤‘Â·ì €í˜¼ì¡í˜•]  RMSE: 41.54 | MAE: 20.06 | RÂ²: 0.9984\n",
      "[Cluster 1 - ìƒì‹œí˜¼ì¡í˜•]  RMSE: 67.90 | MAE: 34.59 | RÂ²: 0.9983\n",
      "\n",
      "ğŸ¯ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "df[\"lag1\"]  = df.groupby(\"intersection\")[\"traffic_volume\"].shift(1)   # 1ì‹œê°„ ì „ êµí†µëŸ‰\n",
    "df[\"lag2\"]  = df.groupby(\"intersection\")[\"traffic_volume\"].shift(2)   # 2ì‹œê°„ ì „ êµí†µëŸ‰  \n",
    "df[\"lag3\"]  = df.groupby(\"intersection\")[\"traffic_volume\"].shift(3)   # 3ì‹œê°„ ì „ êµí†µëŸ‰  \n",
    "\n",
    "df[\"lag24\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(24)    # 24ì‹œê°„ ì „ êµí†µëŸ‰\n",
    "df[\"lag48\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(48)    # 48ì‹œê°„ ì „ êµí†µëŸ‰\n",
    "df['lag72'] = df.groupby(\"intersection\")['traffic_volume'].shift(72)    # 72ì‹œê°„ ì „ êµí†µëŸ‰\n",
    "\n",
    "df[\"roll3\"]  = (    # 3ì‹œê°„ ì´ë™ í‰ê· \n",
    "    df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "    .rolling(3).mean()\n",
    "    .reset_index(0,drop=True)\n",
    ")\n",
    "df[\"roll6\"]  = (    # 6ì‹œê°„ ì´ë™ í‰ê· \n",
    "    df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "    .rolling(6).mean()\n",
    "    .reset_index(0,drop=True)\n",
    ")\n",
    "df[\"roll24\"] = (    # 24ì‹œê°„ ì´ë™ í‰ê· \n",
    "    df.groupby(\"intersection\")[\"traffic_volume\"]\n",
    "    .rolling(24).mean()\n",
    "    .reset_index(0,drop=True)\n",
    ")\n",
    "df['roll48'] = (    # 48ì‹œê°„ ì´ë™ í‰ê· \n",
    "    df.groupby(\"intersection\")['traffic_volume']\n",
    "    .rolling(48).mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df = df.dropna() \n",
    "\n",
    "\n",
    "# ì‹œê°„ íŒŒìƒë³€ìˆ˜\n",
    "df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
    "\n",
    "# Cyclic Encoding\n",
    "df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)      # ì‹œê°„ ì‚¬ì¸ ë³€í™˜\n",
    "df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)      # ì‹œê°„ ì½”ì‚¬ì¸ ë³€í™˜\n",
    "\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dayofweek\"]/7)   # ìš”ì¼ ì‚¬ì¸ ë³€í™˜\n",
    "df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dayofweek\"]/7)   # ìš”ì¼ ì½”ì‚¬ì¸ ë³€í™˜\n",
    "\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ë¶„ë¦¬\n",
    "df_c0 = df[df[\"cluster\"] == 0].copy()   # ì¤‘/ì €í˜¼ì¡í˜•\n",
    "df_c1 = df[df[\"cluster\"] == 1].copy()   # ìƒì‹œí˜¼ì¡í˜•\n",
    "\n",
    "print(\"Cluster 0 ë°ì´í„° ìˆ˜:\", len(df_c0))\n",
    "print(\"Cluster 1 ë°ì´í„° ìˆ˜:\", len(df_c1))\n",
    "\n",
    "\n",
    "# Train/Test ë¶„ë¦¬ í•¨ìˆ˜\n",
    "def split_data(df, test_days=30):\n",
    "    split_date = df[\"date\"].max() - pd.Timedelta(days=test_days)\n",
    "    \n",
    "    train = df[df[\"date\"] <= split_date]\n",
    "    test  = df[df[\"date\"] > split_date]\n",
    "\n",
    "    drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\"]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[\"traffic_volume\"]\n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[\"traffic_volume\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\n",
    "def train_xgb(X_train, y_train):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=1.0,\n",
    "        gamma=1,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = (mean_squared_error(y_test, pred))**0.5\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì‹¤í–‰\n",
    "# --- Cluster 0 ---\n",
    "X_train0, y_train0, X_test0, y_test0 = split_data(df_c0)\n",
    "model0 = train_xgb(X_train0, y_train0)\n",
    "rmse0, mae0, r20 = evaluate(model0, X_test0, y_test0)\n",
    "\n",
    "# --- Cluster 1 ---\n",
    "X_train1, y_train1, X_test1, y_test1 = split_data(df_c1)\n",
    "model1 = train_xgb(X_train1, y_train1)\n",
    "rmse1, mae1, r21 = evaluate(model1, X_test1, y_test1)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥ (ìµœì¢…)\")\n",
    "print(\"==============================\")\n",
    "\n",
    "print(f\"[Cluster 0 - ì¤‘Â·ì €í˜¼ì¡í˜•]  RMSE: {rmse0:.2f} | MAE: {mae0:.2f} | RÂ²: {r20:.4f}\")\n",
    "print(f\"[Cluster 1 - ìƒì‹œí˜¼ì¡í˜•]  RMSE: {rmse1:.2f} | MAE: {mae1:.2f} | RÂ²: {r21:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ¯ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
