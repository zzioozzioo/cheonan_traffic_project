{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2167e338",
   "metadata": {},
   "source": [
    "## ì˜ˆì¸¡ ëª¨ë¸ ì„ ì • ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (LR) RMSE: 1.2985833714843464e-11\n",
      "Baseline (LR) MAE: 9.540694462216198e-12\n",
      "RF RMSE: 95.77556007962038\n",
      "RF MAE: 58.96613497312451\n",
      "XGB RMSE: 60.76022692338509\n",
      "XGB MAE: 36.11786651611328\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"])\n",
    "\n",
    "# 1. Lag Features ìƒì„±\n",
    "df[\"lag1\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(1)\n",
    "df[\"lag2\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(2)\n",
    "df[\"lag3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(3)\n",
    "\n",
    "# Rolling Features\n",
    "df[\"roll3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(3).mean().reset_index(0,drop=True)\n",
    "df[\"roll6\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(6).mean().reset_index(0,drop=True)\n",
    "\n",
    "df = df.dropna()  # lag ë•Œë¬¸ì— ìƒê¸´ NaN ì œê±°\n",
    "\n",
    "\n",
    "# 2. train/test data ë¶„ë¦¬\n",
    "test_size_days = 30 # ìµœê·¼ 30ì¼ì„ testë¡œ ì‚¬ìš©\n",
    "split_date = df[\"date\"].max() - pd.Timedelta(days=test_size_days)\n",
    "\n",
    "train = df[df[\"date\"] <= split_date]\n",
    "test  = df[df[\"date\"] > split_date]\n",
    "\n",
    "drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]  # ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°\n",
    "\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[\"traffic_volume\"]\n",
    "\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[\"traffic_volume\"]\n",
    "\n",
    "\n",
    "# 3. í›„ë³´ 1) ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸(LR)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, pred_lr)\n",
    "rmse_lr = mse_lr ** 0.5\n",
    "mae_lr = mean_absolute_error(y_test, pred_lr)\n",
    "\n",
    "print(\"Baseline (LR) RMSE:\", rmse_lr)\n",
    "print(\"Baseline (LR) MAE:\", mae_lr)\n",
    "\n",
    "\n",
    "# 4. í›„ë³´ 2) RandomForestë¡œ ì˜ˆì¸¡\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, pred_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "mae_rf = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "print(\"RF RMSE:\", rmse_rf)\n",
    "print(\"RF MAE:\", mae_rf)\n",
    "\n",
    "\n",
    "# 5. í›„ë³´ 3) XGBoost ëª¨ë¸\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, pred_xgb)\n",
    "rmse_xgb = mse_xgb ** 0.5\n",
    "mae_xgb = mean_absolute_error(y_test, pred_xgb)\n",
    "\n",
    "print(\"XGB RMSE:\", rmse_xgb)\n",
    "print(\"XGB MAE:\", mae_xgb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb529e4a",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ê¸°ê°„(7, 30, 60, 90ì¼)ë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_days       LR_RMSE        LR_MAE     RF_RMSE      RF_MAE    XGB_RMSE  \\\n",
      "0          7  1.751006e-12  1.361184e-12  224.100296   97.111670  180.762950   \n",
      "1         30  1.477610e-12  1.247242e-12  166.857979   77.414643  141.804429   \n",
      "2         60  1.926105e-11  1.706878e-11  211.395520  105.276260  191.409962   \n",
      "3         90  1.510762e-11  1.336149e-11  208.174734  104.063433  184.863780   \n",
      "\n",
      "      XGB_MAE  \n",
      "0  100.565369  \n",
      "1   83.152451  \n",
      "2  107.258423  \n",
      "3  103.808151  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# -----------------------------------\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "# -----------------------------------\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "target = \"2ê³µë‹¨3\"\n",
    "df = df[df[\"intersection\"] == target].copy()\n",
    "\n",
    "df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "df['lag1'] = df.groupby(\"intersection\")['traffic_volume'].shift(1)\n",
    "df['lag2'] = df.groupby(\"intersection\")['traffic_volume'].shift(2)\n",
    "df['lag3'] = df.groupby(\"intersection\")['traffic_volume'].shift(3)\n",
    "\n",
    "df['roll3'] = df.groupby(\"intersection\")['traffic_volume'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "df['roll6'] = df.groupby(\"intersection\")['traffic_volume'].rolling(6).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# -----------------------------------\n",
    "# ë¹„êµí•  í…ŒìŠ¤íŠ¸ ê¸°ê°„ ëª©ë¡\n",
    "# -----------------------------------\n",
    "test_days_list = [7, 30, 60, 90]\n",
    "\n",
    "results = []\n",
    "\n",
    "drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]\n",
    "\n",
    "for test_days in test_days_list:\n",
    "    split_date = df[\"date\"].max() - pd.Timedelta(days=test_days)\n",
    "\n",
    "    train = df[df[\"date\"] <= split_date]\n",
    "    test = df[df[\"date\"] > split_date]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[\"traffic_volume\"]\n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[\"traffic_volume\"]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1) Linear Regression\n",
    "    # -------------------------------\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred_lr = lr.predict(X_test)\n",
    "\n",
    "    rmse_lr = (mean_squared_error(y_test, pred_lr)) ** 0.5\n",
    "    mae_lr = mean_absolute_error(y_test, pred_lr)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) Random Forest\n",
    "    # -------------------------------\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=50, max_depth=12, random_state=42 # í…ŒìŠ¤íŠ¸ í™˜ê²½ìƒ 50ìœ¼ë¡œ ë‚®ì¶°ì„œ ì§„í–‰\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "\n",
    "    rmse_rf = (mean_squared_error(y_test, pred_rf)) ** 0.5\n",
    "    mae_rf = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) XGBoost\n",
    "    # -------------------------------\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=100, # í…ŒìŠ¤íŠ¸ í™˜ê²½ìƒ 100ìœ¼ë¡œ ë‚®ì¶°ì„œ ì§„í–‰\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "        enable_categorical=False\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "    rmse_xgb = (mean_squared_error(y_test, pred_xgb)) ** 0.5\n",
    "    mae_xgb = mean_absolute_error(y_test, pred_xgb)\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results.append({\n",
    "        \"test_days\": test_days,\n",
    "        \"LR_RMSE\": rmse_lr,\n",
    "        \"LR_MAE\": mae_lr,\n",
    "        \"RF_RMSE\": rmse_rf,\n",
    "        \"RF_MAE\": mae_rf,\n",
    "        \"XGB_RMSE\": rmse_xgb,\n",
    "        \"XGB_MAE\": mae_xgb\n",
    "    })\n",
    "\n",
    "# -----------------------------------\n",
    "# ê²°ê³¼ í‘œ ì¶œë ¥\n",
    "# -----------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3adc73",
   "metadata": {},
   "source": [
    "#### í…ŒìŠ¤íŠ¸ ê²°ê³¼, í˜„ì¬ ë°ì´í„° êµ¬ì¡°ì—ì„œëŠ” XGBoostê°€ ì í•©í•˜ë‹¤ê³  íŒë‹¨ -> XGBoostë¡œ ê³ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ee85a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimeSeriesSplit CV ê²°ê³¼ (Baseline XGB) ===\n",
      "Fold 1 RMSE: 377.05\n",
      "Fold 2 RMSE: 54.08\n",
      "Fold 3 RMSE: 65.44\n",
      "â–¶ í‰ê·  RMSE: 165.52\n",
      "â–¶ í‘œì¤€í¸ì°¨: 149.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------\n",
    "# 1. ë°ì´í„° ì¤€ë¹„\n",
    "# ----------------------------------\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor(\"D\")\n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"])\n",
    "\n",
    "# Lag Features ìƒì„±\n",
    "df[\"lag1\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(1)\n",
    "df[\"lag2\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(2)\n",
    "df[\"lag3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(3)\n",
    "\n",
    "# Rolling Features ìƒì„±\n",
    "df[\"roll3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(3).mean().reset_index(0,drop=True)\n",
    "df[\"roll6\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(6).mean().reset_index(0,drop=True)\n",
    "\n",
    "df = df.dropna()  # lag ë•Œë¬¸ì— ìƒê¸´ NaN ì œê±°\n",
    "\n",
    "# train/test ë¶„ë¦¬\n",
    "test_size_days = 30 # í…ŒìŠ¤íŠ¸ ê¸°ê°„ì„ ë¹„êµí•´ ë³¸ ê²°ê³¼, ìµœê·¼ 30ì¼ ì˜ˆì¸¡ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ê¸°ë¡\n",
    "split_date = df[\"date\"].max() - pd.Timedelta(days=test_size_days)\n",
    "\n",
    "train = df[df[\"date\"] <= split_date]\n",
    "test  = df[df[\"date\"] > split_date]\n",
    "\n",
    "drop_cols = [\"traffic_volume\",\"intersection\",\"datetime\",\"date\",\"slot\"]\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[\"traffic_volume\"]\n",
    "\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[\"traffic_volume\"]\n",
    "\n",
    "\n",
    "# # ----------------------------------\n",
    "# # 2. XGBoost Parameter Space\n",
    "# # ----------------------------------\n",
    "# param_dist = {\n",
    "#     \"n_estimators\": [200, 300, 500, 800],\n",
    "#     \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "#     \"max_depth\": [4, 6, 8, 10],\n",
    "#     \"subsample\": [0.6, 0.8, 1.0],\n",
    "#     \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "#     \"gamma\": [0, 1, 5],\n",
    "#     \"min_child_weight\": [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# ----------------------------------\n",
    "# 3. TimeSeriesSplit ì„¤ì •\n",
    "# ----------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# ----------------------------------\n",
    "# 4. Random Search\n",
    "# ----------------------------------\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=20,              # íƒìƒ‰ íšŸìˆ˜ (ëŠ˜ë¦¬ë©´ ì„±ëŠ¥â†‘, ì‹œê°„â†‘)\n",
    "#     scoring=\"neg_mean_squared_error\",\n",
    "#     cv=tscv,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# ì‹œê³„ì—´ êµì°¨ê²€ì¦\n",
    "cv_scores = cross_val_score(\n",
    "    xgb,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=tscv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rmse_scores = (-cv_scores) ** 0.5\n",
    "\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nğŸ¯ Best Parameters:\")\n",
    "# print(random_search.best_params_)\n",
    "\n",
    "# # ----------------------------------\n",
    "# # 5. ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ\n",
    "# # ----------------------------------\n",
    "# best_model = random_search.best_estimator_\n",
    "\n",
    "# best_model.fit(X_train, y_train)\n",
    "\n",
    "# # ----------------------------------\n",
    "# # 6. Test Set í‰ê°€\n",
    "# # ----------------------------------\n",
    "# pred = best_model.predict(X_test)\n",
    "\n",
    "# mse = mean_squared_error(y_test, pred)\n",
    "# rmse = mse ** 0.5\n",
    "# mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "# print(\"\\nğŸ”¥ Optimized XGBoost ì„±ëŠ¥\")\n",
    "# print(\"RMSE:\", rmse)\n",
    "# print(\"MAE:\", mae)\n",
    "\n",
    "print(\"=== TimeSeriesSplit CV ê²°ê³¼ (Baseline XGB) ===\")\n",
    "for i, s in enumerate(rmse_scores, 1):\n",
    "    print(f\"Fold {i} RMSE: {s:.2f}\")\n",
    "print(f\"â–¶ í‰ê·  RMSE: {rmse_scores.mean():.2f}\")\n",
    "print(f\"â–¶ í‘œì¤€í¸ì°¨: {rmse_scores.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae950c",
   "metadata": {},
   "source": [
    "### í´ëŸ¬ìŠ¤í„°ë³„ ëª¨ë¸ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd6cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ì…‹ êµ¬ì¡°:\n",
      "             datetime intersection  traffic_volume  temp  precipitation  wind  \\\n",
      "0 2024-11-02 00:00:00         2ê³µë‹¨3             341  15.2            0.0   1.1   \n",
      "1 2024-11-02 01:00:00         2ê³µë‹¨3             190  15.6            0.0   1.4   \n",
      "2 2024-11-02 02:00:00         2ê³µë‹¨3             207  14.1            0.0   0.7   \n",
      "3 2024-11-02 03:00:00         2ê³µë‹¨3             180  13.5            0.0   0.5   \n",
      "4 2024-11-02 04:00:00         2ê³µë‹¨3             230  13.2            0.0   0.0   \n",
      "\n",
      "   is_offday       date  hour  dayofweek  month slot  is_rain  cluster  \n",
      "0          1 2024-11-02     0          5     11   ê¸°íƒ€        0        0  \n",
      "1          1 2024-11-02     1          5     11   ê¸°íƒ€        0        0  \n",
      "2          1 2024-11-02     2          5     11   ê¸°íƒ€        0        0  \n",
      "3          1 2024-11-02     3          5     11   ê¸°íƒ€        0        0  \n",
      "4          1 2024-11-02     4          5     11   ê¸°íƒ€        0        0  \n",
      "Feature ìƒì„± ì™„ë£Œ!\n",
      "Cluster 0 ë°ì´í„° ìˆ˜: 345234\n",
      "Cluster 1 ë°ì´í„° ìˆ˜: 260430\n",
      "\n",
      "==============================\n",
      "ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥\n",
      "==============================\n",
      "[Cluster 0 - ì¤‘/ì €í˜¼ì¡í˜•]\n",
      "RMSE: 42.61, MAE: 20.37, RÂ²: 0.9983\n",
      "[Cluster 1 - ìƒì‹œí˜¼ì¡í˜•]\n",
      "RMSE: 69.90, MAE: 35.30, RÂ²: 0.9982\n",
      "\n",
      "ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ============================================================\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "features = pd.read_csv(\"../data/merged/cluster_features.csv\")\n",
    "cluster_map = features[['intersection', 'cluster']]\n",
    "\n",
    "# Merge cluster info\n",
    "df = df.merge(cluster_map, on='intersection', how='left')\n",
    "\n",
    "print(\"ë°ì´í„°ì…‹ êµ¬ì¡°:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Feature Engineering\n",
    "# ============================================================\n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "# Lag Features\n",
    "df['lag1'] = df.groupby(\"intersection\")['traffic_volume'].shift(1)\n",
    "df['lag2'] = df.groupby(\"intersection\")['traffic_volume'].shift(2)\n",
    "df['lag3'] = df.groupby(\"intersection\")['traffic_volume'].shift(3)\n",
    "\n",
    "# More Powerful Lags\n",
    "df['lag24'] = df.groupby(\"intersection\")['traffic_volume'].shift(24)\n",
    "df['lag48'] = df.groupby(\"intersection\")['traffic_volume'].shift(48)\n",
    "df['lag72'] = df.groupby(\"intersection\")['traffic_volume'].shift(72)\n",
    "\n",
    "# Rolling windows\n",
    "df['roll3'] = df.groupby(\"intersection\")['traffic_volume'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "df['roll6'] = df.groupby(\"intersection\")['traffic_volume'].rolling(6).mean().reset_index(level=0, drop=True)\n",
    "df['roll24'] = df.groupby(\"intersection\")['traffic_volume'].rolling(24).mean().reset_index(level=0, drop=True)\n",
    "df['roll48'] = df.groupby(\"intersection\")['traffic_volume'].rolling(48).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Cyclical Encoding (hour, dayofweek)\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "\n",
    "df['dow_sin'] = np.sin(2*np.pi*df['dayofweek']/7)\n",
    "df['dow_cos'] = np.cos(2*np.pi*df['dayofweek']/7)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Feature ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. í´ëŸ¬ìŠ¤í„°ë³„ ë°ì´í„° ë¶„ë¦¬\n",
    "# ============================================================\n",
    "df_c0 = df[df[\"cluster\"] == 0].copy()  # 0: ì¤‘/ì €í˜¼ì¡í˜•\n",
    "df_c1 = df[df[\"cluster\"] == 1].copy()  # 1: ìƒì‹œí˜¼ì¡í˜•\n",
    "\n",
    "print(f\"Cluster 0 ë°ì´í„° ìˆ˜: {len(df_c0)}\")\n",
    "print(f\"Cluster 1 ë°ì´í„° ìˆ˜: {len(df_c1)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Train/Test Split (ìµœê·¼ 30ì¼ test)\n",
    "# ============================================================\n",
    "def split_data(df, test_days=30):\n",
    "    split_date = df[\"date\"].max() - pd.Timedelta(days=test_days)\n",
    "    train = df[df[\"date\"] <= split_date]\n",
    "    test = df[df[\"date\"] > split_date]\n",
    "\n",
    "    drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]\n",
    "\n",
    "    # drop_cols ì œê±°\n",
    "    drop_cols = [col for col in drop_cols if col in df.columns]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[\"traffic_volume\"]\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[\"traffic_volume\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ëª¨ë¸ í•™ìŠµ + í‰ê°€ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def train_xgb(X_train, y_train):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=1.0,\n",
    "        gamma=1,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = (mean_squared_error(y_test, pred))**0.5\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. í´ëŸ¬ìŠ¤í„°ë³„ ëª¨ë¸ í•™ìŠµ\n",
    "# ============================================================\n",
    "\n",
    "# Cluster 0 = ì¤‘/ì €í˜¼ì¡í˜•\n",
    "X_train0, y_train0, X_test0, y_test0 = split_data(df_c0)\n",
    "model0 = train_xgb(X_train0, y_train0)\n",
    "rmse0, mae0, r20 = evaluate(model0, X_test0, y_test0)\n",
    "\n",
    "# Cluster 1 = ìƒì‹œí˜¼ì¡í˜•\n",
    "X_train1, y_train1, X_test1, y_test1 = split_data(df_c1)\n",
    "model1 = train_xgb(X_train1, y_train1)\n",
    "rmse1, mae1, r21 = evaluate(model1, X_test1, y_test1)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. ê²°ê³¼ ì¶œë ¥\n",
    "# ============================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥\")\n",
    "print(\"==============================\")\n",
    "\n",
    "print(f\"[Cluster 0 - ì¤‘/ì €í˜¼ì¡í˜•]\\nRMSE: {rmse0:.2f}, MAE: {mae0:.2f}, RÂ²: {r20:.4f}\")\n",
    "print(f\"[Cluster 1 - ìƒì‹œí˜¼ì¡í˜•]\\nRMSE: {rmse1:.2f}, MAE: {mae1:.2f}, RÂ²: {r21:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
