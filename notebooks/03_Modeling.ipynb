{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2167e338",
   "metadata": {},
   "source": [
    "## ì˜ˆì¸¡ ëª¨ë¸ ì„ ì • ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (LR) RMSE: 1.2985833714843464e-11\n",
      "Baseline (LR) MAE: 9.540694462216198e-12\n",
      "RF RMSE: 95.77556007962038\n",
      "RF MAE: 58.96613497312451\n",
      "XGB RMSE: 60.76022692338509\n",
      "XGB MAE: 36.11786651611328\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"])\n",
    "\n",
    "# 1. Lag Features ìƒì„±\n",
    "df[\"lag1\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(1)\n",
    "df[\"lag2\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(2)\n",
    "df[\"lag3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(3)\n",
    "\n",
    "# Rolling Features\n",
    "df[\"roll3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(3).mean().reset_index(0,drop=True)\n",
    "df[\"roll6\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(6).mean().reset_index(0,drop=True)\n",
    "\n",
    "df = df.dropna()  # lag ë•Œë¬¸ì— ìƒê¸´ NaN ì œê±°\n",
    "\n",
    "\n",
    "# 2. train/test data ë¶„ë¦¬\n",
    "test_size_days = 30 # ìµœê·¼ 30ì¼ì„ testë¡œ ì‚¬ìš©\n",
    "split_date = df[\"date\"].max() - pd.Timedelta(days=test_size_days)\n",
    "\n",
    "train = df[df[\"date\"] <= split_date]\n",
    "test  = df[df[\"date\"] > split_date]\n",
    "\n",
    "drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]  # ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°\n",
    "\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[\"traffic_volume\"]\n",
    "\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[\"traffic_volume\"]\n",
    "\n",
    "\n",
    "# 3. í›„ë³´ 1) ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸(LR)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, pred_lr)\n",
    "rmse_lr = mse_lr ** 0.5\n",
    "mae_lr = mean_absolute_error(y_test, pred_lr)\n",
    "\n",
    "print(\"Baseline (LR) RMSE:\", rmse_lr)\n",
    "print(\"Baseline (LR) MAE:\", mae_lr)\n",
    "\n",
    "\n",
    "# 4. í›„ë³´ 2) RandomForestë¡œ ì˜ˆì¸¡\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, pred_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "mae_rf = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "print(\"RF RMSE:\", rmse_rf)\n",
    "print(\"RF MAE:\", mae_rf)\n",
    "\n",
    "\n",
    "# 5. í›„ë³´ 3) XGBoost ëª¨ë¸\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, pred_xgb)\n",
    "rmse_xgb = mse_xgb ** 0.5\n",
    "mae_xgb = mean_absolute_error(y_test, pred_xgb)\n",
    "\n",
    "print(\"XGB RMSE:\", rmse_xgb)\n",
    "print(\"XGB MAE:\", mae_xgb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb529e4a",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ê¸°ê°„(7, 30, 60, 90ì¼)ë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_days       LR_RMSE        LR_MAE     RF_RMSE      RF_MAE    XGB_RMSE  \\\n",
      "0          7  1.751006e-12  1.361184e-12  224.100296   97.111670  180.762950   \n",
      "1         30  1.477610e-12  1.247242e-12  166.857979   77.414643  141.804429   \n",
      "2         60  1.926105e-11  1.706878e-11  211.395520  105.276260  191.409962   \n",
      "3         90  1.510762e-11  1.336149e-11  208.174734  104.063433  184.863780   \n",
      "\n",
      "      XGB_MAE  \n",
      "0  100.565369  \n",
      "1   83.152451  \n",
      "2  107.258423  \n",
      "3  103.808151  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# -----------------------------------\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "# -----------------------------------\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "target = \"2ê³µë‹¨3\"\n",
    "df = df[df[\"intersection\"] == target].copy()\n",
    "\n",
    "df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "df['lag1'] = df.groupby(\"intersection\")['traffic_volume'].shift(1)\n",
    "df['lag2'] = df.groupby(\"intersection\")['traffic_volume'].shift(2)\n",
    "df['lag3'] = df.groupby(\"intersection\")['traffic_volume'].shift(3)\n",
    "\n",
    "df['roll3'] = df.groupby(\"intersection\")['traffic_volume'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "df['roll6'] = df.groupby(\"intersection\")['traffic_volume'].rolling(6).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# -----------------------------------\n",
    "# ë¹„êµí•  í…ŒìŠ¤íŠ¸ ê¸°ê°„ ëª©ë¡\n",
    "# -----------------------------------\n",
    "test_days_list = [7, 30, 60, 90]\n",
    "\n",
    "results = []\n",
    "\n",
    "drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]\n",
    "\n",
    "for test_days in test_days_list:\n",
    "    split_date = df[\"date\"].max() - pd.Timedelta(days=test_days)\n",
    "\n",
    "    train = df[df[\"date\"] <= split_date]\n",
    "    test = df[df[\"date\"] > split_date]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[\"traffic_volume\"]\n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[\"traffic_volume\"]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1) Linear Regression\n",
    "    # -------------------------------\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred_lr = lr.predict(X_test)\n",
    "\n",
    "    rmse_lr = (mean_squared_error(y_test, pred_lr)) ** 0.5\n",
    "    mae_lr = mean_absolute_error(y_test, pred_lr)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) Random Forest\n",
    "    # -------------------------------\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=50, max_depth=12, random_state=42 # í…ŒìŠ¤íŠ¸ í™˜ê²½ìƒ 50ìœ¼ë¡œ ë‚®ì¶°ì„œ ì§„í–‰\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "\n",
    "    rmse_rf = (mean_squared_error(y_test, pred_rf)) ** 0.5\n",
    "    mae_rf = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) XGBoost\n",
    "    # -------------------------------\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=100, # í…ŒìŠ¤íŠ¸ í™˜ê²½ìƒ 100ìœ¼ë¡œ ë‚®ì¶°ì„œ ì§„í–‰\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "        enable_categorical=False\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "    rmse_xgb = (mean_squared_error(y_test, pred_xgb)) ** 0.5\n",
    "    mae_xgb = mean_absolute_error(y_test, pred_xgb)\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results.append({\n",
    "        \"test_days\": test_days,\n",
    "        \"LR_RMSE\": rmse_lr,\n",
    "        \"LR_MAE\": mae_lr,\n",
    "        \"RF_RMSE\": rmse_rf,\n",
    "        \"RF_MAE\": mae_rf,\n",
    "        \"XGB_RMSE\": rmse_xgb,\n",
    "        \"XGB_MAE\": mae_xgb\n",
    "    })\n",
    "\n",
    "# -----------------------------------\n",
    "# ê²°ê³¼ í‘œ ì¶œë ¥\n",
    "# -----------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3adc73",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ê²°ê³¼, í˜„ì¬ ë°ì´í„° êµ¬ì¡°ì—ì„œëŠ” XGBoostê°€ ì í•©í•˜ë‹¤ê³  íŒë‹¨ -> XGBoostë¡œ ê³ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ee85a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimeSeriesSplit CV ê²°ê³¼ (Baseline XGB) ===\n",
      "Fold 1 RMSE: 377.05\n",
      "Fold 2 RMSE: 54.08\n",
      "Fold 3 RMSE: 65.44\n",
      "â–¶ í‰ê·  RMSE: 165.52\n",
      "â–¶ í‘œì¤€í¸ì°¨: 149.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------\n",
    "# 1. ë°ì´í„° ì¤€ë¹„\n",
    "# ----------------------------------\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor(\"D\")\n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"])\n",
    "\n",
    "# Lag Features ìƒì„±\n",
    "df[\"lag1\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(1)\n",
    "df[\"lag2\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(2)\n",
    "df[\"lag3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].shift(3)\n",
    "\n",
    "# Rolling Features ìƒì„±\n",
    "df[\"roll3\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(3).mean().reset_index(0,drop=True)\n",
    "df[\"roll6\"] = df.groupby(\"intersection\")[\"traffic_volume\"].rolling(6).mean().reset_index(0,drop=True)\n",
    "\n",
    "df = df.dropna()  # lag ë•Œë¬¸ì— ìƒê¸´ NaN ì œê±°\n",
    "\n",
    "# train/test ë¶„ë¦¬\n",
    "test_size_days = 30 # í…ŒìŠ¤íŠ¸ ê¸°ê°„ì„ ë¹„êµí•´ ë³¸ ê²°ê³¼, ìµœê·¼ 30ì¼ ì˜ˆì¸¡ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ê¸°ë¡\n",
    "split_date = df[\"date\"].max() - pd.Timedelta(days=test_size_days)\n",
    "\n",
    "train = df[df[\"date\"] <= split_date]\n",
    "test  = df[df[\"date\"] > split_date]\n",
    "\n",
    "drop_cols = [\"traffic_volume\",\"intersection\",\"datetime\",\"date\",\"slot\"]\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[\"traffic_volume\"]\n",
    "\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[\"traffic_volume\"]\n",
    "\n",
    "\n",
    "# # ----------------------------------\n",
    "# # 2. XGBoost Parameter Space\n",
    "# # ----------------------------------\n",
    "# param_dist = {\n",
    "#     \"n_estimators\": [200, 300, 500, 800],\n",
    "#     \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "#     \"max_depth\": [4, 6, 8, 10],\n",
    "#     \"subsample\": [0.6, 0.8, 1.0],\n",
    "#     \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "#     \"gamma\": [0, 1, 5],\n",
    "#     \"min_child_weight\": [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# ----------------------------------\n",
    "# 3. TimeSeriesSplit ì„¤ì •\n",
    "# ----------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# ----------------------------------\n",
    "# 4. Random Search\n",
    "# ----------------------------------\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=20,              # íƒìƒ‰ íšŸìˆ˜ (ëŠ˜ë¦¬ë©´ ì„±ëŠ¥â†‘, ì‹œê°„â†‘)\n",
    "#     scoring=\"neg_mean_squared_error\",\n",
    "#     cv=tscv,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# ì‹œê³„ì—´ êµì°¨ê²€ì¦\n",
    "cv_scores = cross_val_score(\n",
    "    xgb,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=tscv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rmse_scores = (-cv_scores) ** 0.5\n",
    "\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nğŸ¯ Best Parameters:\")\n",
    "# print(random_search.best_params_)\n",
    "\n",
    "# # ----------------------------------\n",
    "# # 5. ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ\n",
    "# # ----------------------------------\n",
    "# best_model = random_search.best_estimator_\n",
    "\n",
    "# best_model.fit(X_train, y_train)\n",
    "\n",
    "# # ----------------------------------\n",
    "# # 6. Test Set í‰ê°€\n",
    "# # ----------------------------------\n",
    "# pred = best_model.predict(X_test)\n",
    "\n",
    "# mse = mean_squared_error(y_test, pred)\n",
    "# rmse = mse ** 0.5\n",
    "# mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "# print(\"\\nğŸ”¥ Optimized XGBoost ì„±ëŠ¥\")\n",
    "# print(\"RMSE:\", rmse)\n",
    "# print(\"MAE:\", mae)\n",
    "\n",
    "print(\"=== TimeSeriesSplit CV ê²°ê³¼ (Baseline XGB) ===\")\n",
    "for i, s in enumerate(rmse_scores, 1):\n",
    "    print(f\"Fold {i} RMSE: {s:.2f}\")\n",
    "print(f\"â–¶ í‰ê·  RMSE: {rmse_scores.mean():.2f}\")\n",
    "print(f\"â–¶ í‘œì¤€í¸ì°¨: {rmse_scores.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd6cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ì…‹ êµ¬ì¡°:\n",
      "             datetime intersection  traffic_volume  temp  precipitation  wind  \\\n",
      "0 2024-11-02 00:00:00         2ê³µë‹¨3             341  15.2            0.0   1.1   \n",
      "1 2024-11-02 01:00:00         2ê³µë‹¨3             190  15.6            0.0   1.4   \n",
      "2 2024-11-02 02:00:00         2ê³µë‹¨3             207  14.1            0.0   0.7   \n",
      "3 2024-11-02 03:00:00         2ê³µë‹¨3             180  13.5            0.0   0.5   \n",
      "4 2024-11-02 04:00:00         2ê³µë‹¨3             230  13.2            0.0   0.0   \n",
      "\n",
      "   is_offday       date  hour  dayofweek  month slot  is_rain  cluster  \n",
      "0          1 2024-11-02     0          5     11   ê¸°íƒ€        0        0  \n",
      "1          1 2024-11-02     1          5     11   ê¸°íƒ€        0        0  \n",
      "2          1 2024-11-02     2          5     11   ê¸°íƒ€        0        0  \n",
      "3          1 2024-11-02     3          5     11   ê¸°íƒ€        0        0  \n",
      "4          1 2024-11-02     4          5     11   ê¸°íƒ€        0        0  \n",
      "Feature ìƒì„± ì™„ë£Œ!\n",
      "Cluster 0 ë°ì´í„° ìˆ˜: 345234\n",
      "Cluster 1 ë°ì´í„° ìˆ˜: 260430\n",
      "\n",
      "==============================\n",
      "ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥\n",
      "==============================\n",
      "[Cluster 0 - ì¤‘/ì €í˜¼ì¡í˜•]\n",
      "RMSE: 42.61, MAE: 20.37\n",
      "[Cluster 1 - ìƒì‹œí˜¼ì¡í˜•]\n",
      "RMSE: 69.90, MAE: 35.30\n",
      "\n",
      "ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ============================================================\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "features = pd.read_csv(\"../data/merged/cluster_features.csv\")\n",
    "cluster_map = features[['intersection', 'cluster']]\n",
    "\n",
    "# Merge cluster info\n",
    "df = df.merge(cluster_map, on='intersection', how='left')\n",
    "\n",
    "print(\"ë°ì´í„°ì…‹ êµ¬ì¡°:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Feature Engineering\n",
    "# ============================================================\n",
    "\n",
    "df = df.sort_values([\"intersection\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "# Lag Features\n",
    "df['lag1'] = df.groupby(\"intersection\")['traffic_volume'].shift(1)\n",
    "df['lag2'] = df.groupby(\"intersection\")['traffic_volume'].shift(2)\n",
    "df['lag3'] = df.groupby(\"intersection\")['traffic_volume'].shift(3)\n",
    "\n",
    "# More Powerful Lags\n",
    "df['lag24'] = df.groupby(\"intersection\")['traffic_volume'].shift(24)\n",
    "df['lag48'] = df.groupby(\"intersection\")['traffic_volume'].shift(48)\n",
    "df['lag72'] = df.groupby(\"intersection\")['traffic_volume'].shift(72)\n",
    "\n",
    "# Rolling windows\n",
    "df['roll3'] = df.groupby(\"intersection\")['traffic_volume'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "df['roll6'] = df.groupby(\"intersection\")['traffic_volume'].rolling(6).mean().reset_index(level=0, drop=True)\n",
    "df['roll24'] = df.groupby(\"intersection\")['traffic_volume'].rolling(24).mean().reset_index(level=0, drop=True)\n",
    "df['roll48'] = df.groupby(\"intersection\")['traffic_volume'].rolling(48).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Cyclical Encoding (hour, dayofweek)\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "\n",
    "df['dow_sin'] = np.sin(2*np.pi*df['dayofweek']/7)\n",
    "df['dow_cos'] = np.cos(2*np.pi*df['dayofweek']/7)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Feature ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. í´ëŸ¬ìŠ¤í„°ë³„ ë°ì´í„° ë¶„ë¦¬\n",
    "# ============================================================\n",
    "df_c0 = df[df[\"cluster\"] == 0].copy()  # 0: ì¤‘/ì €í˜¼ì¡í˜•\n",
    "df_c1 = df[df[\"cluster\"] == 1].copy()  # 1: ìƒì‹œí˜¼ì¡í˜•\n",
    "\n",
    "print(f\"Cluster 0 ë°ì´í„° ìˆ˜: {len(df_c0)}\")\n",
    "print(f\"Cluster 1 ë°ì´í„° ìˆ˜: {len(df_c1)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Train/Test Split (ìµœê·¼ 30ì¼ test)\n",
    "# ============================================================\n",
    "def split_data(df, test_days=30):\n",
    "    split_date = df[\"date\"].max() - pd.Timedelta(days=test_days)\n",
    "    train = df[df[\"date\"] <= split_date]\n",
    "    test = df[df[\"date\"] > split_date]\n",
    "\n",
    "    drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]\n",
    "\n",
    "    # drop_cols ì œê±°\n",
    "    drop_cols = [col for col in drop_cols if col in df.columns]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[\"traffic_volume\"]\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[\"traffic_volume\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ëª¨ë¸ í•™ìŠµ + í‰ê°€ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def train_xgb(X_train, y_train):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=1.0,\n",
    "        gamma=1,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    rmse = (mean_squared_error(y_test, pred))**0.5\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    return rmse, mae\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. í´ëŸ¬ìŠ¤í„°ë³„ ëª¨ë¸ í•™ìŠµ\n",
    "# ============================================================\n",
    "\n",
    "# Cluster 0 = ì¤‘/ì €í˜¼ì¡í˜•\n",
    "X_train0, y_train0, X_test0, y_test0 = split_data(df_c0)\n",
    "model0 = train_xgb(X_train0, y_train0)\n",
    "rmse0, mae0 = evaluate(model0, X_test0, y_test0)\n",
    "\n",
    "# Cluster 1 = ìƒì‹œí˜¼ì¡í˜•\n",
    "X_train1, y_train1, X_test1, y_test1 = split_data(df_c1)\n",
    "model1 = train_xgb(X_train1, y_train1)\n",
    "rmse1, mae1 = evaluate(model1, X_test1, y_test1)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. ê²°ê³¼ ì¶œë ¥\n",
    "# ============================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥\")\n",
    "print(\"==============================\")\n",
    "\n",
    "print(f\"[Cluster 0 - ì¤‘/ì €í˜¼ì¡í˜•]\\nRMSE: {rmse0:.2f}, MAE: {mae0:.2f}\")\n",
    "print(f\"[Cluster 1 - ìƒì‹œí˜¼ì¡í˜•]\\nRMSE: {rmse1:.2f}, MAE: {mae1:.2f}\")\n",
    "\n",
    "print(\"\\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dce560",
   "metadata": {},
   "source": [
    "### í´ëŸ¬ìŠ¤í„°ë§ ê·¸ë£¹ë³„ë¡œ êµí†µëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ë ¤ê³  í–ˆìœ¼ë‚˜, ê°™ì€ ê·¸ë£¹ì´ë¼ê³  í•´ë„ ì‚¬ì‹¤ìƒ ê°œë³„ êµì°¨ë¡œë³„ë¡œ íŒ¨í„´ì´ ë‹¬ë¼ í˜¼ì¡ë„ í¸ì¤‘ì´ ì‹¬í•œ í˜„ìƒì´ ë°œìƒí•¨. ë”°ë¼ì„œ, ì‹¤ì œ ì¤‘ìš”í•œ êµ¬ê°„ì¸ ìƒì‹œí˜¼ì¡í˜•ì— ì§‘ì¤‘í•´ ëª¨ë¸ì„ ì •êµí™”í•˜ê¸°ë¡œ í–ˆìŒ. ì¦‰, ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œë³„ ê°œë³„ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒ. -> ë¬¸ì œ ìˆëŠ” êµ¬ê°„ì„ ì°¾ì•„ ê·¸ êµ¬ê°„ì„ ì§‘ì¤‘ ê°œì„ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00077064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œ ê°œìˆ˜: 31\n",
      "['ê³ ì¬4' 'êµ¬ì„±3' 'êµ´ìš¸(ë³€ì „ì†Œ)4' 'ë‚¨ë¶€5' 'ë„ë¡œì›ì 3' 'ë°©ì•„ë‹¤ë¦¬(ì´ë§ˆíŠ¸)4' 'ë²ˆì˜ë¡œ(ê°¤ëŸ¬ë¦¬ì•„)4' 'ë¶ˆë‹¹4'\n",
      " 'ë¶ˆë‹¹í˜„ëŒ€4' 'ì‚¼ì„±ì „ê´€3' 'ìƒˆë§(í•œë¼APTì…êµ¬)4' 'ì„±ì •ë¡¯ë°4' 'ì‹œì²­4' 'ìŒìš©ë„ì„œê´€3' 'ìŒìš©ë™4' 'ìŒìš©ì´ˆêµ4'\n",
      " 'ì—¬ì„±íšŒê´€4' 'ìš©ì•”4' 'ì›í˜•ìœ¡êµ4' 'ì´ìˆ˜(3ì‚°ì—…)4' 'ì¸ì‡„ì°½4' 'ì¼ë´‰ì‚°4' 'ì²œì•ˆëŒ€ë¡œ4' 'ì²­ë‹¹ë™ì…êµ¬4' 'ì²­ì‚¼4'\n",
      " 'í•˜ì‹ 3' 'ë‘ì •ì—­ì‚¬ê±°ë¦¬' 'ë°±ì„ì‚¬ê±°ë¦¬' 'ë°±ì„ì¶©ì „ì†Œì‚¬ê±°ë¦¬' 'ì„œë¶€ëŒ€ë¡œì‚¬ê±°ë¦¬' 'í•œë“¤ì‚¬ê±°ë¦¬']\n",
      "\n",
      "ë°ì´í„° í™•ì¸:\n",
      "              datetime intersection  traffic_volume  temp  precipitation  \\\n",
      "48 2024-11-02 00:00:00          ê³ ì¬4             492  15.2            0.0   \n",
      "49 2024-11-02 01:00:00          ê³ ì¬4             359  15.6            0.0   \n",
      "50 2024-11-02 02:00:00          ê³ ì¬4             351  14.1            0.0   \n",
      "51 2024-11-02 03:00:00          ê³ ì¬4             284  13.5            0.0   \n",
      "52 2024-11-02 04:00:00          ê³ ì¬4             378  13.2            0.0   \n",
      "\n",
      "    wind  is_offday       date  hour  dayofweek  month slot  is_rain  cluster  \n",
      "48   1.1          1 2024-11-02     0          5     11   ê¸°íƒ€        0        1  \n",
      "49   1.4          1 2024-11-02     1          5     11   ê¸°íƒ€        0        1  \n",
      "50   0.7          1 2024-11-02     2          5     11   ê¸°íƒ€        0        1  \n",
      "51   0.5          1 2024-11-02     3          5     11   ê¸°íƒ€        0        1  \n",
      "52   0.0          1 2024-11-02     4          5     11   ê¸°íƒ€        0        1  \n",
      "âœ… ì™„ë£Œ: ê³ ì¬4 | RMSE=110.84, MAE=56.68\n",
      "âœ… ì™„ë£Œ: êµ¬ì„±3 | RMSE=128.66, MAE=65.05\n",
      "âœ… ì™„ë£Œ: êµ´ìš¸(ë³€ì „ì†Œ)4 | RMSE=97.56, MAE=50.90\n",
      "âœ… ì™„ë£Œ: ë‚¨ë¶€5 | RMSE=63.93, MAE=42.74\n",
      "âœ… ì™„ë£Œ: ë„ë¡œì›ì 3 | RMSE=107.29, MAE=56.48\n",
      "âœ… ì™„ë£Œ: ë°©ì•„ë‹¤ë¦¬(ì´ë§ˆíŠ¸)4 | RMSE=72.40, MAE=47.03\n",
      "âœ… ì™„ë£Œ: ë²ˆì˜ë¡œ(ê°¤ëŸ¬ë¦¬ì•„)4 | RMSE=109.32, MAE=72.82\n",
      "âœ… ì™„ë£Œ: ë¶ˆë‹¹4 | RMSE=255.61, MAE=140.89\n",
      "âœ… ì™„ë£Œ: ë¶ˆë‹¹í˜„ëŒ€4 | RMSE=233.98, MAE=125.09\n",
      "âœ… ì™„ë£Œ: ì‚¼ì„±ì „ê´€3 | RMSE=228.56, MAE=123.83\n",
      "âœ… ì™„ë£Œ: ìƒˆë§(í•œë¼APTì…êµ¬)4 | RMSE=119.30, MAE=77.27\n",
      "âœ… ì™„ë£Œ: ì„±ì •ë¡¯ë°4 | RMSE=58.20, MAE=40.54\n",
      "âœ… ì™„ë£Œ: ì‹œì²­4 | RMSE=203.98, MAE=114.61\n",
      "âœ… ì™„ë£Œ: ìŒìš©ë„ì„œê´€3 | RMSE=70.24, MAE=48.54\n",
      "âœ… ì™„ë£Œ: ìŒìš©ë™4 | RMSE=92.45, MAE=58.57\n",
      "âœ… ì™„ë£Œ: ìŒìš©ì´ˆêµ4 | RMSE=68.86, MAE=47.32\n",
      "âœ… ì™„ë£Œ: ì—¬ì„±íšŒê´€4 | RMSE=80.65, MAE=52.18\n",
      "âœ… ì™„ë£Œ: ìš©ì•”4 | RMSE=82.78, MAE=55.41\n",
      "âœ… ì™„ë£Œ: ì›í˜•ìœ¡êµ4 | RMSE=94.70, MAE=65.14\n",
      "âœ… ì™„ë£Œ: ì´ìˆ˜(3ì‚°ì—…)4 | RMSE=207.54, MAE=113.87\n",
      "âœ… ì™„ë£Œ: ì¸ì‡„ì°½4 | RMSE=77.36, MAE=53.67\n",
      "âœ… ì™„ë£Œ: ì¼ë´‰ì‚°4 | RMSE=82.24, MAE=53.48\n",
      "âœ… ì™„ë£Œ: ì²œì•ˆëŒ€ë¡œ4 | RMSE=166.41, MAE=83.66\n",
      "âœ… ì™„ë£Œ: ì²­ë‹¹ë™ì…êµ¬4 | RMSE=140.69, MAE=72.37\n",
      "âœ… ì™„ë£Œ: ì²­ì‚¼4 | RMSE=157.10, MAE=87.91\n",
      "âœ… ì™„ë£Œ: í•˜ì‹ 3 | RMSE=94.84, MAE=60.49\n",
      "âœ… ì™„ë£Œ: ë‘ì •ì—­ì‚¬ê±°ë¦¬ | RMSE=63.53, MAE=44.46\n",
      "âœ… ì™„ë£Œ: ë°±ì„ì‚¬ê±°ë¦¬ | RMSE=74.95, MAE=50.21\n",
      "âœ… ì™„ë£Œ: ë°±ì„ì¶©ì „ì†Œì‚¬ê±°ë¦¬ | RMSE=86.25, MAE=56.56\n",
      "âœ… ì™„ë£Œ: ì„œë¶€ëŒ€ë¡œì‚¬ê±°ë¦¬ | RMSE=69.24, MAE=48.84\n",
      "âœ… ì™„ë£Œ: í•œë“¤ì‚¬ê±°ë¦¬ | RMSE=88.80, MAE=57.23\n",
      "\n",
      "==============================\n",
      "ğŸ“Œ ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œë³„ ì˜ˆì¸¡ ì„±ëŠ¥\n",
      "==============================\n",
      "    intersection        RMSE         MAE\n",
      "11         ì„±ì •ë¡¯ë°4   58.198509   40.544102\n",
      "26        ë‘ì •ì—­ì‚¬ê±°ë¦¬   63.525082   44.461121\n",
      "3            ë‚¨ë¶€5   63.929370   42.739101\n",
      "15         ìŒìš©ì´ˆêµ4   68.861614   47.317490\n",
      "29       ì„œë¶€ëŒ€ë¡œì‚¬ê±°ë¦¬   69.240202   48.844391\n",
      "13        ìŒìš©ë„ì„œê´€3   70.242715   48.541103\n",
      "5     ë°©ì•„ë‹¤ë¦¬(ì´ë§ˆíŠ¸)4   72.403849   47.026920\n",
      "27         ë°±ì„ì‚¬ê±°ë¦¬   74.949371   50.205437\n",
      "20          ì¸ì‡„ì°½4   77.360153   53.668068\n",
      "16         ì—¬ì„±íšŒê´€4   80.648643   52.181652\n",
      "21          ì¼ë´‰ì‚°4   82.242520   53.484295\n",
      "17           ìš©ì•”4   82.776699   55.413280\n",
      "28      ë°±ì„ì¶©ì „ì†Œì‚¬ê±°ë¦¬   86.246232   56.560703\n",
      "30         í•œë“¤ì‚¬ê±°ë¦¬   88.801135   57.231339\n",
      "14          ìŒìš©ë™4   92.452062   58.568527\n",
      "18         ì›í˜•ìœ¡êµ4   94.703464   65.135559\n",
      "25           í•˜ì‹ 3   94.842030   60.485386\n",
      "2       êµ´ìš¸(ë³€ì „ì†Œ)4   97.560979   50.900696\n",
      "4          ë„ë¡œì›ì 3  107.292701   56.478775\n",
      "6     ë²ˆì˜ë¡œ(ê°¤ëŸ¬ë¦¬ì•„)4  109.318691   72.821281\n",
      "0            ê³ ì¬4  110.837631   56.680008\n",
      "10  ìƒˆë§(í•œë¼APTì…êµ¬)4  119.300279   77.273048\n",
      "1            êµ¬ì„±3  128.658242   65.048515\n",
      "23        ì²­ë‹¹ë™ì…êµ¬4  140.688014   72.366951\n",
      "24           ì²­ì‚¼4  157.095786   87.906876\n",
      "22         ì²œì•ˆëŒ€ë¡œ4  166.413207   83.660416\n",
      "12           ì‹œì²­4  203.979798  114.614609\n",
      "19      ì´ìˆ˜(3ì‚°ì—…)4  207.543811  113.874153\n",
      "9          ì‚¼ì„±ì „ê´€3  228.562124  123.831078\n",
      "8          ë¶ˆë‹¹í˜„ëŒ€4  233.975510  125.085175\n",
      "7            ë¶ˆë‹¹4  255.609031  140.886780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° + í´ëŸ¬ìŠ¤í„° ì •ë³´ ë³‘í•©\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../data/merged/traffic_weather_features.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.floor('D')\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„°ë§ ì •ë³´\n",
    "features = pd.read_csv(\"../data/merged/cluster_features.csv\")\n",
    "df = df.merge(features[['intersection', 'cluster']], on='intersection', how='left')\n",
    "\n",
    "# ìƒì‹œí˜¼ì¡í˜•ë§Œ ì„ íƒ (cluster=1)\n",
    "df_hot = df[df['cluster'] == 1].copy()\n",
    "\n",
    "print(f\"ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œ ê°œìˆ˜: {df_hot['intersection'].nunique()}\")\n",
    "print(df_hot['intersection'].unique())\n",
    "print(\"\\në°ì´í„° í™•ì¸:\")\n",
    "print(df_hot.head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Feature Engineering í•¨ìˆ˜ (êµì°¨ë¡œë³„ ì ìš©)\n",
    "# ============================================================\n",
    "def add_features(df_sub):\n",
    "    df_sub = df_sub.sort_values(\"datetime\").copy()\n",
    "\n",
    "    # Lag features\n",
    "    df_sub['lag1'] = df_sub['traffic_volume'].shift(1)\n",
    "    df_sub['lag2'] = df_sub['traffic_volume'].shift(2)\n",
    "    df_sub['lag3'] = df_sub['traffic_volume'].shift(3)\n",
    "    df_sub['lag24'] = df_sub['traffic_volume'].shift(24)\n",
    "\n",
    "    # Rolling\n",
    "    df_sub['roll3'] = df_sub['traffic_volume'].rolling(3).mean()\n",
    "    df_sub['roll6'] = df_sub['traffic_volume'].rolling(6).mean()\n",
    "    df_sub['roll24'] = df_sub['traffic_volume'].rolling(24).mean()\n",
    "\n",
    "    # Time features\n",
    "    df_sub['hour'] = df_sub['datetime'].dt.hour\n",
    "    df_sub['dayofweek'] = df_sub['datetime'].dt.dayofweek\n",
    "\n",
    "    df_sub['hour_sin'] = np.sin(2*np.pi*df_sub['hour']/24)\n",
    "    df_sub['hour_cos'] = np.cos(2*np.pi*df_sub['hour']/24)\n",
    "\n",
    "    df_sub['dow_sin'] = np.sin(2*np.pi*df_sub['dayofweek']/7)\n",
    "    df_sub['dow_cos'] = np.cos(2*np.pi*df_sub['dayofweek']/7)\n",
    "\n",
    "    df_sub = df_sub.dropna()\n",
    "    return df_sub\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Train/Test Split í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def split_data(df_sub, test_days=30):\n",
    "    split_date = df_sub['date'].max() - pd.Timedelta(days=test_days)\n",
    "    train = df_sub[df_sub['date'] <= split_date]\n",
    "    test = df_sub[df_sub['date'] > split_date]\n",
    "\n",
    "    drop_cols = [\"traffic_volume\", \"intersection\", \"datetime\", \"date\", \"slot\"]\n",
    "    drop_cols = [c for c in drop_cols if c in df_sub.columns]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[\"traffic_volume\"]\n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[\"traffic_volume\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. XGBoost í›ˆë ¨ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def train_xgb(X_train, y_train):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.07,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ê°œë³„ êµì°¨ë¡œ ëª¨ë¸ í•™ìŠµ\n",
    "# ============================================================\n",
    "results = []\n",
    "\n",
    "hot_intersections = df_hot['intersection'].unique()\n",
    "\n",
    "for inter in hot_intersections:\n",
    "    df_sub = df_hot[df_hot['intersection'] == inter].copy()\n",
    "    df_sub = add_features(df_sub)\n",
    "\n",
    "    if len(df_sub) < 200:\n",
    "        print(f\"âŒ ë°ì´í„° ì ìŒ â†’ ìŠ¤í‚µ: {inter}\")\n",
    "        continue\n",
    "\n",
    "    X_train, y_train, X_test, y_test = split_data(df_sub)\n",
    "\n",
    "    model = train_xgb(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    rmse = (mean_squared_error(y_test, pred))**0.5\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "    results.append([inter, rmse, mae])\n",
    "\n",
    "    print(f\"âœ… ì™„ë£Œ: {inter} | RMSE={rmse:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. ê²°ê³¼ ì •ë¦¬\n",
    "# ============================================================\n",
    "results_df = pd.DataFrame(results, columns=[\"intersection\", \"RMSE\", \"MAE\"])\n",
    "results_df = results_df.sort_values(\"RMSE\")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"ğŸ“Œ ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œë³„ ì˜ˆì¸¡ ì„±ëŠ¥\")\n",
    "print(\"==============================\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5e21c",
   "metadata": {},
   "source": [
    "### ê·¸ëŸ°ë° ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œì˜ ê°œë³„ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì—ì„œë„ ë¬¸ì œê°€ ìƒê¹€. ê°œë³„ êµì°¨ë¡œ ë°ì´í„°ë¥¼ train/testë¡œ ë‚˜ëˆ„ë‹¤ë³´ë‹ˆ ë°ì´í„°ê°€ ë¶€ì¡± -> variance í­ì¦!! ëª¨ë“  êµì°¨ë¡œê°€ ì™„ì „íˆ ë…ë¦½ëœ ëª¨ë¸ì´ ëê¸° ë•Œë¬¸. ë˜í•œ ìƒì‹œí˜¼ì¡í˜• êµì°¨ë¡œëŠ” ë³€ë™ì„±ì´ ë§¤ìš° ì»¤ì„œ RMSEê°€ ë†’ê²Œ ë‚˜ì˜¬ ë¿ë”ëŸ¬ ê° êµì°¨ë¡œë§ˆë‹¤ íŒ¨í„´ ìì²´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ(êµ°ì§‘ì„ í•œ ë²ˆ ë” ì„¸ë¶„í™”í•´ì•¼ í•  ê°€ëŠ¥ì„±)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a468b8",
   "metadata": {},
   "source": [
    "1ï¸âƒ£ ë¬¸ì œ ì •ì˜\n",
    "\n",
    "êµì°¨ë¡œë³„ ì‹œê°„ëŒ€ êµí†µëŸ‰ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³  ìˆìŒ.\n",
    "â†’ ì‹ í˜¸ ìµœì í™”, í˜¼ì¡ ê´€ë¦¬ì— í™œìš©í•˜ë ¤ëŠ” ëª©ì .\n",
    "\n",
    "2ï¸âƒ£ ì§€ê¸ˆê¹Œì§€ í•œ ì¼\n",
    "\n",
    "ë‚ ì”¨ + ì‹œê°„ + ìš”ì¼ + lag + rolling ë“± ê¸°ë³¸ feature ìƒì„±\n",
    "\n",
    "LR / RandomForest / XGBoost ë¹„êµ\n",
    "â†’ XGBoostê°€ ê°€ì¥ ì¢‹ìŒ\n",
    "\n",
    "ë‹¨, ìƒì‹œí˜¼ì¡ êµì°¨ë¡œëŠ” ë³€ë™ì„±ì´ ë„ˆë¬´ ì»¤ì„œ RMSEê°€ ë†’ê²Œ ë‚˜ì˜´.\n",
    "\n",
    "3ï¸âƒ£ í´ëŸ¬ìŠ¤í„°ë§ ì ìš©\n",
    "\n",
    "êµì°¨ë¡œë³„ í‰ê· /í‘œì¤€í¸ì°¨/í”¼í¬/ë‚ ì”¨ë°˜ì‘ ë“±ìœ¼ë¡œ KMeans\n",
    "\n",
    "2ê°œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ë‰¨:\n",
    "\n",
    "Cluster 0 = ì¤‘Â·ì €í˜¼ì¡í˜•\n",
    "\n",
    "Cluster 1 = ìƒì‹œí˜¼ì¡í˜•\n",
    "\n",
    "4ï¸âƒ£ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ëª¨ë¸ë§\n",
    "\n",
    "ì²˜ìŒ ì‹œë„: â€œí´ëŸ¬ìŠ¤í„°ë³„ 1ê°œ ëª¨ë¸â€\n",
    "â†’ ì„±ëŠ¥ ê°œì„  ê±°ì˜ ì—†ìŒ.\n",
    "\n",
    "5ï¸âƒ£ í˜„ì¬ ì‹œë„ ì¤‘\n",
    "\n",
    "**ìƒì‹œí˜¼ì¡ êµì°¨ë¡œë“¤(31ê³³)**ë§Œ ë”°ë¡œ\n",
    "â†’ êµì°¨ë¡œë³„ ê°œë³„ XGBoost ëª¨ë¸ ìƒì„±\n",
    "\n",
    "ê²°ê³¼: RMSEëŠ” ë‹¤ì†Œ í¬ì§€ë§Œ, ìƒì‹œí˜¼ì¡ íŠ¹ì„±ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ìˆ˜ì¤€\n",
    "(ê¸°ë³¸ êµí†µëŸ‰ ìì²´ê°€ í¬ê³  ë³€ë™í­ì´ ì»¤ì„œ ì˜¤ì°¨ë„ ìì—°íˆ í¼)\n",
    "\n",
    "6ï¸âƒ£ ì§€ê¸ˆ ë§ë‹¥ëœ¨ë¦° í•µì‹¬ ë¬¸ì œ\n",
    "\n",
    "ìƒì‹œí˜¼ì¡í˜•ì€ ë³€ë™ì´ ì‹¬í•¨\n",
    "\n",
    "êµì°¨ë¡œë³„ ë°ì´í„° ìˆ˜ê°€ ì ì–´ì„œ í•˜ë‚˜ì˜ ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì–´ë ¤ì›€\n",
    "\n",
    "í˜„ì¬ featureë§Œìœ¼ë¡œëŠ” ê° êµì°¨ë¡œ ê³ ìœ  íŒ¨í„´ì„ ì¶©ë¶„íˆ í‘œí˜„í•˜ì§€ ëª»í•¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
